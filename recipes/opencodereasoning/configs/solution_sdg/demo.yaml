cluster: local
base_output_dir: /workspace/recipes/opencodereasoning/data/  # Base output directory for all experiments
expname: ocr-demo
suffix: toy  # Suffix for experiment names


# Input file for the first stage (generate_solutions)
# This should be the output of the problem_generation.py pipeline
input_file: ${base_output_dir}/open_code_reasoning_questions.jsonl

num_random_seeds_to_generate: 1
# Can define initial dependency for the `generate_solutions` stage to run after
initial_dependency: ${expname}-prepare-questions

# Define the full sequence of stages for this mode
pipeline_stages:
  - generate_solutions          # Generate initial solutions
  - filter_solutions            # Filter solutions which dont follow format

# Directory structure configuration
directories:
  step-1-generate-solutions: ${base_output_dir}/solution-sdg-${suffix}/generation
  step-2-filter-solutions: ${base_output_dir}/solution-sdg-${suffix}/filtered

# Stage-specific configurations
stages:
  generate_solutions:
    output_dir: ${directories.step-1-generate-solutions}
    input_file: ${input_file}
    language: python  # Language of the solutions to generate
    # Arguments passed inside the generate context string (e.g., ++param=value)
    inline_args: "++inference.tokens_to_generate=8192 ++generation_key='output' ++inference.temperature=0.6"
    # Arguments passed as kwargs to the pipeline function (e.g. generate())
    stage_kwargs:
      model: deepseek-ai/deepseek-r1-distill-qwen-32b
      server_type: openai
      server_address: https://integrate.api.nvidia.com/v1
      num_random_seeds: ${num_random_seeds_to_generate}

  filter_solutions:
    output_dir: ${directories.step-2-filter-solutions}
    input_dir: ${directories.step-1-generate-solutions}
    language: ${stages.generate_solutions.language}
    dependencies:
      - generate_solutions
